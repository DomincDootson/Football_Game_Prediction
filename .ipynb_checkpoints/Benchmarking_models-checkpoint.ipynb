{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ffbcb4a-f60e-4a8a-b68e-4e35e520d058",
   "metadata": {},
   "source": [
    "# Benchmarking Models "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d172df2-6b62-4f07-b0aa-6168a7bd8a03",
   "metadata": {},
   "source": [
    "So in this notebook we will take the different data set, fit models and test their accuracy. From this hopefully we will find the best data to be using and hopefully gain some insight into out models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a6e5ed84-6f6f-4e7e-a11d-ba192fa41d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "49ca30eb-b281-4362-a1f8-7d05c987aad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_benchmark = pd.read_csv(\"Benchmarks/Benchmark_dataset.csv\")\n",
    "train_full = pd.read_csv(\"full_train_data.csv\")\n",
    "train_Without_avg = pd.read_csv(\"without_avg_train.csv\")\n",
    "train_Without_avg_BS_S = pd.read_csv(\"without_avg_train_BS_S.csv\")\n",
    "train_Without_avg_BS_S_sum = pd.read_csv(\"without_avg_train_BS_S_sum.csv\")\n",
    "\n",
    "                            \n",
    "train_scores = pd.read_csv('Train_Data/Y_train.csv', index_col=0)\n",
    "train_scores = train_scores.loc[train_benchmark.index] # This is our target\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342c9273-1c68-475b-98bd-88699defe9e5",
   "metadata": {},
   "source": [
    "## Modelling Wins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e50919d-770f-4a2a-9738-71e48846c213",
   "metadata": {},
   "source": [
    "In order to best compare to the benchmark given on the website we will start by trying to predict the number of wins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55520ac1-5724-4f0d-bbe4-1a7215af5336",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y_AWAY_WINS = train_scores['AWAY_WINS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1351e924-de2b-47dd-93c5-5c9fb15698da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_valid_test(X, y):\n",
    "    X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, train_size=0.8, random_state=42)\n",
    "    X_train, X_valid, y_train, y_valid = model_selection.train_test_split(X_train, y_train, train_size=0.8, random_state=42)\n",
    "\n",
    "    return X_train, X_valid, X_test, y_train, y_valid, y_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "450f4294-10d9-4036-85e1-d3c2199e3a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_1D_predictions(predictions):\n",
    "    predictions[2] = 0 # This will mean that no draws are predicted\n",
    "    predictions.columns = [0,2,1] # This labels the columns correctly\n",
    "    return (predictions.reindex(columns=[0,1,2]).rank(1,ascending=False)==1).astype(int).values # This reorders the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a9465653-3fcc-4bdf-98c5-7f060fc910a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_Benchmark_params = {\n",
    "    'booster': 'gbtree',\n",
    "    'tree_method':'hist',\n",
    "    'max_depth': 8, \n",
    "    'learning_rate': 0.025,\n",
    "    'objective': 'multi:softprob',\n",
    "    'num_class': 2,\n",
    "    'eval_metric': 'mlogloss'\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a345b77d-2401-4186-8a2b-30f18bd6e9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction_score(model, X_test, y_test):\n",
    "    predictions = model.predict(X_test, iteration_range=(0, model.best_iteration))\n",
    "    predictions = pd.DataFrame(predictions)\n",
    "    \n",
    "    predictions = format_1D_predictions(predictions)\n",
    "    \n",
    "    \n",
    "    target = train_scores.loc[X_test.index].copy()\n",
    "    sns.heatmap(confusion_matrix(predictions, target.to_numpy()))\n",
    "    \n",
    "    return np.round(accuracy_score(predictions,target),4), np.round(f1_score(predictions,target) , 4)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d7fc2813-3f98-4d1a-b3be-abed62f3320c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_1D_XGB(training_data, replace_0_with_nan = False, XGB_params = XGB_Benchmark_params):\n",
    "    X_train, X_valid, X_test, y_train, y_valid, y_test = get_train_valid_test(training_data, train_y_AWAY_WINS)\n",
    "    \n",
    "    if replace_0_with_nan:\n",
    "        X_train = X_train.replace({0:np.nan})\n",
    "    \n",
    "    xgb_model = xgb.XGBClassifier(random_state=42, **XGB_params)\n",
    "    bst = xgb_model.fit(X_train, y_train)\n",
    "    \n",
    "    test_acc, train_acc, f1 = get_prediction_score(xgb_model,X_test,y_test), get_prediction_score(xgb_model,X_train,y_train)\n",
    "    \n",
    "    print(f\"Test accuracy: {test_acc}; Training accuracy: {train_acc}\")\n",
    "    return xgb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a7bbfdaf-ac72-4eab-85f9-a8a33be60554",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "multilabel-indicator is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[86], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m training_1D_XGB(train_benchmark, \u001b[38;5;28;01mFalse\u001b[39;00m); \n\u001b[1;32m      2\u001b[0m XGB_bench \u001b[38;5;241m=\u001b[39m training_1D_XGB(train_benchmark, \u001b[38;5;28;01mTrue\u001b[39;00m); \n\u001b[1;32m      3\u001b[0m training_1D_XGB(train_full); \n",
      "Cell \u001b[0;32mIn[85], line 10\u001b[0m, in \u001b[0;36mtraining_1D_XGB\u001b[0;34m(training_data, replace_0_with_nan, XGB_params)\u001b[0m\n\u001b[1;32m      7\u001b[0m xgb_model \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mXGBClassifier(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mXGB_params)\n\u001b[1;32m      8\u001b[0m bst \u001b[38;5;241m=\u001b[39m xgb_model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m---> 10\u001b[0m test_acc, train_acc \u001b[38;5;241m=\u001b[39m get_prediction_score(xgb_model,X_test,y_test), get_prediction_score(xgb_model,X_train,y_train)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_acc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m; Training accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_acc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xgb_model\n",
      "Cell \u001b[0;32mIn[84], line 9\u001b[0m, in \u001b[0;36mget_prediction_score\u001b[0;34m(model, X_test, y_test)\u001b[0m\n\u001b[1;32m      5\u001b[0m predictions \u001b[38;5;241m=\u001b[39m format_1D_predictions(predictions)\n\u001b[1;32m      8\u001b[0m target \u001b[38;5;241m=\u001b[39m train_scores\u001b[38;5;241m.\u001b[39mloc[X_test\u001b[38;5;241m.\u001b[39mindex]\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m----> 9\u001b[0m sns\u001b[38;5;241m.\u001b[39mheatmap(confusion_matrix(predictions, target\u001b[38;5;241m.\u001b[39mto_numpy()))\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mround(accuracy_score(predictions,target),\u001b[38;5;241m4\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:319\u001b[0m, in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    317\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 319\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m y_type)\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    322\u001b[0m     labels \u001b[38;5;241m=\u001b[39m unique_labels(y_true, y_pred)\n",
      "\u001b[0;31mValueError\u001b[0m: multilabel-indicator is not supported"
     ]
    }
   ],
   "source": [
    "training_1D_XGB(train_benchmark, False); \n",
    "XGB_bench = training_1D_XGB(train_benchmark, True); \n",
    "training_1D_XGB(train_full); \n",
    "XGB_without_avg = training_1D_XGB(train_Without_avg); # I think that this is our best model \n",
    "training_1D_XGB(train_Without_avg_BS_S);\n",
    "training_1D_XGB(train_Without_avg_BS_S_sum);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92567a6b-250f-42d0-a344-76898f1d2ed0",
   "metadata": {},
   "source": [
    " Okay, so I think the best data set we have is train_without_avg_BS_S_Sum. But we note that there is some serious overfitting going on. Note that we aren't predicting draws, therefore a 'perfect' score would be ~75% (25% are draws)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52655cc-a3b2-4ca4-8220-ffba3c3f1cdd",
   "metadata": {},
   "source": [
    "## Modelling all Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef437658-1511-4398-80a8-8ce21642371b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
