{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ffbcb4a-f60e-4a8a-b68e-4e35e520d058",
   "metadata": {},
   "source": [
    "# Benchmarking Models "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d172df2-6b62-4f07-b0aa-6168a7bd8a03",
   "metadata": {},
   "source": [
    "So in this notebook we will take the different data set, fit models and test their accuracy. From this hopefully we will find the best data to be using and hopefully gain some insight into out models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a6e5ed84-6f6f-4e7e-a11d-ba192fa41d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49ca30eb-b281-4362-a1f8-7d05c987aad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_benchmark = pd.read_csv(\"Benchmarks/Benchmark_dataset.csv\")\n",
    "train_full = pd.read_csv(\"full_train_data.csv\")\n",
    "train_Without_avg = pd.read_csv(\"without_avg_train.csv\")\n",
    "train_Without_avg_BS_S = pd.read_csv(\"without_avg_train_BS_S.csv\")\n",
    "train_Without_avg_BS_S_sum = pd.read_csv(\"without_avg_train_BS_S_sum.csv\")\n",
    "\n",
    "                            \n",
    "train_scores = pd.read_csv('Train_Data/Y_train.csv', index_col=0)\n",
    "train_scores = train_scores.loc[train_benchmark.index] # This is our target\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342c9273-1c68-475b-98bd-88699defe9e5",
   "metadata": {},
   "source": [
    "## Modelling Wins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e50919d-770f-4a2a-9738-71e48846c213",
   "metadata": {},
   "source": [
    "In order to best compare to the benchmark given on the website we will start by trying to predict the number of wins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55520ac1-5724-4f0d-bbe4-1a7215af5336",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y_AWAY_WINS = train_scores['AWAY_WINS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1351e924-de2b-47dd-93c5-5c9fb15698da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_valid_test(X, y):\n",
    "    X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, train_size=0.8, random_state=42)\n",
    "    X_train, X_valid, y_train, y_valid = model_selection.train_test_split(X_train, y_train, train_size=0.8, random_state=42)\n",
    "\n",
    "    return X_train, X_valid, X_test, y_train, y_valid, y_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "450f4294-10d9-4036-85e1-d3c2199e3a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_1D_predictions(predictions):\n",
    "    predictions[2] = 0 # This will mean that no draws are predicted\n",
    "    predictions.columns = [0,2,1] # This labels the columns correctly\n",
    "    return (predictions.reindex(columns=[0,1,2]).rank(1,ascending=False)==1).astype(int).values # This reorders the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9465653-3fcc-4bdf-98c5-7f060fc910a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_Benchmark_params = {\n",
    "    'booster': 'gbtree',\n",
    "    'tree_method':'hist',\n",
    "    'max_depth': 8, \n",
    "    'learning_rate': 0.025,\n",
    "    'objective': 'multi:softprob',\n",
    "    'num_class': 2,\n",
    "    'eval_metric': 'mlogloss'\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a345b77d-2401-4186-8a2b-30f18bd6e9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction_score(model, X_test, y_test):\n",
    "    predictions = model.predict(X_test, iteration_range=(0, model.best_iteration))\n",
    "    predictions = pd.DataFrame(predictions)\n",
    "    \n",
    "    predictions = format_1D_predictions(predictions)\n",
    "    \n",
    "    target = train_scores.loc[X_test.index].copy()\n",
    "    return np.round(accuracy_score(predictions,target),4)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7fc2813-3f98-4d1a-b3be-abed62f3320c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_1D_XGB(training_data, replace_0_with_nan = False, XGB_params = XGB_Benchmark_params):\n",
    "    X_train, X_valid, X_test, y_train, y_valid, y_test = get_train_valid_test(training_data, train_y_AWAY_WINS)\n",
    "    \n",
    "    if replace_0_with_nan:\n",
    "        X_train = X_train.replace({0:np.nan})\n",
    "    \n",
    "    xgb_model = xgb.XGBClassifier(random_state=42, **XGB_params)\n",
    "    bst = xgb_model.fit(X_train, y_train)\n",
    "    \n",
    "    test_acc, train_acc = get_prediction_score(xgb_model,X_test,y_test), get_prediction_score(xgb_model,X_train,y_train)\n",
    "    \n",
    "    print(f\"Test accuracy: {test_acc}; Training accuracy: {train_acc}\")\n",
    "    return xgb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a7bbfdaf-ac72-4eab-85f9-a8a33be60554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.4689; Training accuracy: 0.6847\n",
      "Test accuracy: 0.4742; Training accuracy: 0.7071\n",
      "Test accuracy: 0.4722; Training accuracy: 0.669\n",
      "Test accuracy: 0.4791; Training accuracy: 0.679\n",
      "Test accuracy: 0.477; Training accuracy: 0.6624\n",
      "Test accuracy: 0.4779; Training accuracy: 0.6369\n"
     ]
    }
   ],
   "source": [
    "training_1D_XGB(train_benchmark, False); \n",
    "XGB_bench = training_1D_XGB(train_benchmark, True); \n",
    "training_1D_XGB(train_full); \n",
    "XGB_without_avg = training_1D_XGB(train_Without_avg); # I think that this is our best model \n",
    "training_1D_XGB(train_Without_avg_BS_S);\n",
    "training_1D_XGB(train_Without_avg_BS_S_sum);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92567a6b-250f-42d0-a344-76898f1d2ed0",
   "metadata": {},
   "source": [
    "Okay, so I think the best data set we have is train_without_avg_BS_S_Sum. But we note that there is some serious overfitting going on. Note that we aren't predicting draws, therefore a 'perfect' score would be ~75% (25% are draws). \n",
    "\n",
    "I want to plot the confusion matrcies of the this: I think we are basically just predicting the home team wins\n",
    "Let's create some functions to generate the analytics of this data set and consider how to preceed. A few things that need to be dealt with:\n",
    "1. I think we are overfitting the data (Difference in test/train scores)\n",
    "2. The model is trying to just predict the most common class (i.e. wins) and the improvement is only slight upon this"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52655cc-a3b2-4ca4-8220-ffba3c3f1cdd",
   "metadata": {},
   "source": [
    "## Modelling all Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c6a37068-68d9-4c1d-a168-c216549fd55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_encoder(y, mapping = {tuple([1, 0, 0]): 2, tuple([0, 1, 0]): 1, tuple([0, 0, 1]): 0}):\n",
    "    return (y.apply(lambda x : mapping[tuple(x)], axis = 1)).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "14db2b22-c0f5-4dd0-812a-b3e4e671a39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_Benchmark_params_multi = {\n",
    "    'booster': 'gbtree',\n",
    "    'tree_method':'hist',\n",
    "    'max_depth': 8, \n",
    "    'learning_rate': 0.025,\n",
    "    'objective': 'multi:softprob',\n",
    "    'num_class': 3,\n",
    "    'eval_metric': 'mlogloss'\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ef437658-1511-4398-80a8-8ce21642371b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_3D_XGB(training_data, XGB_params = XGB_Benchmark_params_multi):\n",
    "    X_train, X_valid, X_test, y_train, y_valid, y_test = get_train_valid_test(training_data, train_scores)\n",
    "    \n",
    "    \n",
    "    y_train_encoded = class_encoder(y_train)\n",
    "    y_test_encoded = class_encoder(y_test)\n",
    "    \n",
    "    # Initialize XGBoost classifier\n",
    "    model = xgb.XGBClassifier(random_state=42, **XGB_params)\n",
    "    model.fit(X_train, y_train_encoded)\n",
    "    \n",
    "    # Predict the labels for the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # plt.hist(y_pred, bins = 3, density=True)\n",
    "    print(confusion_matrix(y_test_encoded, y_pred))\n",
    "    \n",
    "    # Evaluate accuracy\n",
    "    test_acc, train_acc = accuracy_score(y_test_encoded, y_pred), accuracy_score(y_train_encoded, model.predict(X_train))\n",
    "    test_f1, train_f1 = f1_score(y_test_encoded, y_pred, average='weighted'), f1_score(y_train_encoded, model.predict(X_train), average='weighted')\n",
    "    print(f\"Test accuracy: {np.round(test_acc,4)}; Training accuracy: {np.round(train_acc,4)}\")\n",
    "    print(f\"Test f1: {np.round(test_f1,4)}; Training f1: {np.round(train_f1,4)}\")\n",
    "    print(f\"{'-'*40}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ba90cdb3-c0f1-4990-a3dc-b49522fe6be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[327  48 383]\n",
      " [173  37 410]\n",
      " [206  56 821]]\n",
      "Test accuracy: 0.4815; Training accuracy: 0.9592\n",
      "Test f1: 0.43; Training f1: 0.9591\n",
      "----------------------------------------\n",
      "[[318  66 374]\n",
      " [174  53 393]\n",
      " [190  72 821]]\n",
      "Test accuracy: 0.4844; Training accuracy: 0.9564\n",
      "Test f1: 0.4395; Training f1: 0.9565\n",
      "----------------------------------------\n",
      "[[301  68 389]\n",
      " [178  43 399]\n",
      " [205  65 813]]\n",
      "Test accuracy: 0.4701; Training accuracy: 0.9552\n",
      "Test f1: 0.4224; Training f1: 0.9551\n",
      "----------------------------------------\n",
      "[[307  66 385]\n",
      " [183  51 386]\n",
      " [208  76 799]]\n",
      "Test accuracy: 0.4701; Training accuracy: 0.9473\n",
      "Test f1: 0.4266; Training f1: 0.9472\n",
      "----------------------------------------\n",
      "[[304  62 392]\n",
      " [168  39 413]\n",
      " [181  73 829]]\n",
      "Test accuracy: 0.4762; Training accuracy: 0.9153\n",
      "Test f1: 0.426; Training f1: 0.9151\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "XGB_bench = training_3D_XGB(train_benchmark); \n",
    "training_3D_XGB(train_full); \n",
    "XGB_without_avg = training_3D_XGB(train_Without_avg); \n",
    "training_3D_XGB(train_Without_avg_BS_S);\n",
    "training_3D_XGB(train_Without_avg_BS_S_sum);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31879673-8192-4a16-a6e9-1fa3572d3b8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
